{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e1cc430fb409>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholtwinters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExponentialSmoothing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholtwinters\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleExpSmoothing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec  19 14:44:06 2019\n",
    "\n",
    "@author: Mohamed.Imran\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn import linear_model\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from fbprophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\jayac\\Downloads\\Data science\\Day 17\\TS_Decomposition_Data_Workingfile.csv\") #Read your decomposition file here\n",
    "\n",
    "#Regression model\n",
    "def Regression(data):\n",
    "    data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
    "    data=data.sort_values([\"Date\"])\n",
    "    data[\"Quarter\"] = data[\"Date\"].dt.quarter\n",
    "    data[\"Year\"] = data[\"Date\"].dt.year\n",
    "    data[\"Month\"] = data[\"Date\"].dt.month\n",
    "    \n",
    "    Train=data[(data.Year>=2015)&(data.Year<2019)] #modify date according to your dataset; Train : 2017-2018\n",
    "    Test=data[(data.Year==2019)]  #modify date according to your dataset; Test : 2019\n",
    "    \n",
    "    \n",
    "    Train[\"SI_Y\"]=Train[\"Volume\"]/Train.groupby(\"Year\")[\"Volume\"].transform(np.mean)\n",
    "    Train[\"F_SI\"]=Train.groupby(\"Month\")[\"SI_Y\"].transform(np.mean)\n",
    "    Train[\"D_Seasonalised_trend\"] = Train[\"Volume\"]/Train[\"F_SI\"]    \n",
    "    Train[\"Level_index1\"]=np.mean(Train[(Train.Year==2018)&(Train.Quarter==1)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2017)&(Train.Quarter==4)][\"D_Seasonalised_trend\"])\n",
    "    \n",
    "    numer1=np.mean(Train[(Train.Year==2018)&(Train.Quarter==3)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2018)&(Train.Quarter==2)][\"D_Seasonalised_trend\"])\n",
    "    numer2=np.mean(Train[(Train.Year==2018)&(Train.Quarter==4)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2018)&(Train.Quarter==3)][\"D_Seasonalised_trend\"])\n",
    "    \n",
    "    \n",
    "    Train[\"Level_index2\"]=np.mean([numer1,numer2])\n",
    "    Train=Train.sort_values([\"Date\"])\n",
    "    Train.index=range(len(Train))\n",
    "    Train[\"ID\"]=range(1,(len(Train)+1))\n",
    "    \n",
    "    Train[\"Deleveled_series\"]=np.where(Train.Year==2017, Train[\"D_Seasonalised_trend\"]*Train[\"Level_index1\"],Train[\"D_Seasonalised_trend\"])\n",
    "    \n",
    "    lm = linear_model.LinearRegression()\n",
    "    X = np.array(Train[[\"ID\", \"Variable_1\"]]) # In case of no extra variable in the dataset, remove the extra variable name from the list, then append the line with \".reshape(-1, 1)\"\n",
    "    Y = np.array(Train[\"Deleveled_series\"]).reshape(-1,1)\n",
    "    \n",
    "    model = lm.fit(X,Y)\n",
    "    \n",
    "    Test[\"ID\"]=range(len(Test))\n",
    "    Test[\"ID\"]=Test[\"ID\"]+max(Train[\"ID\"])\n",
    "    X_test=np.array(Test[[\"ID\", \"Variable_1\"]]) # In case of no extra variable in the dataset, remove the extra variable name from the list, then append the line with \".reshape(-1, 1)\"\n",
    "    Y_test=model.predict(X_test)\n",
    "    \n",
    "    Pred1 = Y_test*Train.iloc[0][\"Level_index2\"]*np.array(Train.iloc[0:len(Y_test)][\"F_SI\"]).reshape(-1,1)\n",
    "    Test[\"Predictions\"]=Pred1\n",
    "    \n",
    "    return(Test['Predictions'])\n",
    "\n",
    "#Arima model\n",
    "def Arima(data): \n",
    "    X = data['Volume'].values\n",
    "    size = np.sum(data['Date']<='12/31/2018')\n",
    "    train, test = X[0:size], X[size:len(X)]\n",
    "    history = [x for x in train]\n",
    "    predictions = list()  \n",
    "        \n",
    "    for t in range(len(test)):\n",
    "    \tmodel = ARIMA(history, order=(1,1,0))\n",
    "    \tmodel_fit = model.fit(disp=0)\n",
    "    \toutput = model_fit.forecast()\n",
    "    \tyhat = output[0]\n",
    "    \tpredictions.append(yhat)\n",
    "    \tobs = test[t]\n",
    "    \thistory.append(obs)\n",
    "    return predictions   \n",
    "\n",
    "#Holts-Winter model\n",
    "def Holts_winter(data):\n",
    "    inter_df = data[['Volume']]\n",
    "    size = np.sum(data['Date']<='12/31/2018')\n",
    "    train, test = inter_df.iloc[:size, 0], inter_df.iloc[size:, 0]\n",
    "    model = ExponentialSmoothing(train, seasonal='mul', seasonal_periods=12).fit()\n",
    "    pred = model.predict(start=test.index[0], end=test.index[-1])\n",
    "    return pred\n",
    "\n",
    "#Fbprophet\n",
    "def Fbprophet(data):\n",
    "    size = np.sum(data['ds']<='12/31/2018')\n",
    "    inter_df = data.iloc[:size, :]\n",
    "    m = Prophet(weekly_seasonality=False, daily_seasonality=False)\n",
    "    m.fit(inter_df)\n",
    "    future = m.make_future_dataframe(periods=12, freq='M')\n",
    "    forecast = m.predict(future)\n",
    "    fcst = forecast['yhat'].tail(12)\n",
    "    return fcst\n",
    "\n",
    "#Simple Exponential Smoothing model\n",
    "def Ses(data):\n",
    "    inter_df = data[['Volume']]\n",
    "    size = np.sum(data['Date']<='12/31/2018')\n",
    "    train, test = inter_df.iloc[:size, 0], inter_df.iloc[size:, 0]\n",
    "    model = SimpleExpSmoothing(train).fit()\n",
    "    pred = model.predict(start=test.index[0], end=test.index[-1])\n",
    "    return pred\n",
    "\n",
    "\n",
    "\n",
    "def Regression_2lag(data):\n",
    "    data[\"Variable_1\"] = data[\"Variable_1\"].shift(2)\n",
    "    data = data.loc[2:, :]\n",
    "    return Regression(data)\n",
    "\n",
    "\n",
    "required_cols = [col for col in data.columns if col not in ['Date', 'Variable_1']]\n",
    "\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "\n",
    "for model in [Regression, Arima, Holts_winter, Ses, Fbprophet, Regression_2lag]:\n",
    "    for i in required_cols:\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "        to_func = data[[\"Date\", \"Variable_1\", i]]\n",
    "        to_func.columns=[\"Date\",\"Variable_1\", \"Volume\"]\n",
    "        if model == Fbprophet:\n",
    "            to_func.columns=[\"ds\",\"Variable_1\", \"y\"]\n",
    "            Result_inter = model(to_func[['ds', 'y']])\n",
    "            Result_inter.name = model.__name__ + \"_\" +  i\n",
    "            Result_inter.index = range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n",
    "        elif model == Arima:\n",
    "            Result_inter = model(to_func)\n",
    "            Result_inter = pd.DataFrame(Result_inter, columns = [\"ARIMA_\" + i])\n",
    "            Result_inter.index=range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n",
    "        else:\n",
    "            Result_inter = model(to_func)\n",
    "            Result_inter.name = model.__name__ + \"_\" +  i\n",
    "            Result_inter.index=range(len(Result_inter))\n",
    "            Result = pd.concat([Result, Result_inter], axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "Result.to_csv('Forecast.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\jayac\\Downloads\\Data science\\Day 17\\decom2 example.csv\") #Read your decomposition file here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Marketing spends</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>1508.25</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>1956.76</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2133.19</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>1813.04</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1203.39</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Marketing spends  Quarter  Year  Month\n",
       "19 2018-08-01           1508.25        3  2018      8\n",
       "20 2018-09-01           1956.76        3  2018      9\n",
       "21 2018-10-01           2133.19        4  2018     10\n",
       "22 2018-11-01           1813.04        4  2018     11\n",
       "23 2018-12-01           1203.39        4  2018     12"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"],format='%d-%m-%Y')\n",
    "data=data.sort_values([\"Date\"])\n",
    "data[\"Quarter\"] = data[\"Date\"].dt.quarter\n",
    "data[\"Year\"] = data[\"Date\"].dt.year\n",
    "data[\"Month\"] = data[\"Date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Marketing spends':'Volume'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "Train=data[(data.Year>=2017)&(data.Year<=2018)] #modify date according to your dataset; Train : 2017-2018\n",
    "Test=data[(data.Year==2019)]  #modify date according to your dataset; Test : 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"SI_Y\"]=Train[\"Volume\"]/Train.groupby(\"Year\")[\"Volume\"].transform(np.mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"F_SI\"]=Train.groupby(\"Month\")[\"SI_Y\"].transform(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"F_SI\"]=Train.groupby(\"Month\")[\"SI_Y\"].transform(np.mean)\n",
    "Train[\"D_Seasonalised_trend\"] = Train[\"Volume\"]/Train[\"F_SI\"]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"Level_index1\"]=np.mean(Train[(Train.Year==2018)&(Train.Quarter==1)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2017)&(Train.Quarter==4)][\"D_Seasonalised_trend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "numer1=np.mean(Train[(Train.Year==2018)&(Train.Quarter==3)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2018)&(Train.Quarter==2)][\"D_Seasonalised_trend\"])\n",
    "numer2=np.mean(Train[(Train.Year==2018)&(Train.Quarter==4)][\"D_Seasonalised_trend\"])/np.mean(Train[(Train.Year==2018)&(Train.Quarter==3)][\"D_Seasonalised_trend\"])\n",
    "\n",
    "Train[\"Level_index2\"]=np.mean([numer1,numer2])\n",
    "Train=Train.sort_values([\"Date\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>SI_Y</th>\n",
       "      <th>F_SI</th>\n",
       "      <th>D_Seasonalised_trend</th>\n",
       "      <th>Level_index1</th>\n",
       "      <th>Level_index2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1942.21</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.911636</td>\n",
       "      <td>0.997334</td>\n",
       "      <td>1947.402409</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>1749.93</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.821383</td>\n",
       "      <td>0.934584</td>\n",
       "      <td>1872.416839</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2399.42</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>1.126241</td>\n",
       "      <td>1.070109</td>\n",
       "      <td>2242.220419</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2126.85</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998302</td>\n",
       "      <td>1.005148</td>\n",
       "      <td>2115.957015</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2242.50</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>1.052586</td>\n",
       "      <td>1.056178</td>\n",
       "      <td>2123.221263</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2436.44</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>1.143618</td>\n",
       "      <td>1.013425</td>\n",
       "      <td>2404.164082</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>2016.88</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0.946684</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>2036.460337</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>1755.23</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>0.823871</td>\n",
       "      <td>0.837916</td>\n",
       "      <td>2094.756233</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2149.94</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>1.009140</td>\n",
       "      <td>1.057225</td>\n",
       "      <td>2033.568875</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2905.47</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>1.363771</td>\n",
       "      <td>1.284370</td>\n",
       "      <td>2262.174524</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2338.88</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>1.097825</td>\n",
       "      <td>1.060976</td>\n",
       "      <td>2204.460646</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>1501.86</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>0.704944</td>\n",
       "      <td>0.692350</td>\n",
       "      <td>2169.221130</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1917.32</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1.083032</td>\n",
       "      <td>0.997334</td>\n",
       "      <td>1922.445867</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1854.92</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>1.047784</td>\n",
       "      <td>0.934584</td>\n",
       "      <td>1984.755644</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>1795.07</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1.013977</td>\n",
       "      <td>1.070109</td>\n",
       "      <td>1677.464807</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>1791.56</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>1.011994</td>\n",
       "      <td>1.005148</td>\n",
       "      <td>1782.384254</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>1876.14</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "      <td>1.059771</td>\n",
       "      <td>1.056178</td>\n",
       "      <td>1776.347978</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>1563.61</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>0.883232</td>\n",
       "      <td>1.013425</td>\n",
       "      <td>1542.896603</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>1830.67</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1.034086</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>1848.442567</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>1508.25</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>0.851961</td>\n",
       "      <td>0.837916</td>\n",
       "      <td>1800.001190</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>1956.76</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>1.105310</td>\n",
       "      <td>1.057225</td>\n",
       "      <td>1850.845248</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2133.19</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>1.204970</td>\n",
       "      <td>1.284370</td>\n",
       "      <td>1660.883806</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>1813.04</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>1.024127</td>\n",
       "      <td>1.060976</td>\n",
       "      <td>1708.841552</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>1203.39</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.679756</td>\n",
       "      <td>0.692350</td>\n",
       "      <td>1738.124070</td>\n",
       "      <td>0.841589</td>\n",
       "      <td>1.003384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Volume  Quarter  Year  Month      SI_Y      F_SI  \\\n",
       "0  2017-01-01  1942.21        1  2017      1  0.911636  0.997334   \n",
       "1  2017-02-01  1749.93        1  2017      2  0.821383  0.934584   \n",
       "2  2017-03-01  2399.42        1  2017      3  1.126241  1.070109   \n",
       "3  2017-04-01  2126.85        2  2017      4  0.998302  1.005148   \n",
       "4  2017-05-01  2242.50        2  2017      5  1.052586  1.056178   \n",
       "5  2017-06-01  2436.44        2  2017      6  1.143618  1.013425   \n",
       "6  2017-07-01  2016.88        3  2017      7  0.946684  0.990385   \n",
       "7  2017-08-01  1755.23        3  2017      8  0.823871  0.837916   \n",
       "8  2017-09-01  2149.94        3  2017      9  1.009140  1.057225   \n",
       "9  2017-10-01  2905.47        4  2017     10  1.363771  1.284370   \n",
       "10 2017-11-01  2338.88        4  2017     11  1.097825  1.060976   \n",
       "11 2017-12-01  1501.86        4  2017     12  0.704944  0.692350   \n",
       "12 2018-01-01  1917.32        1  2018      1  1.083032  0.997334   \n",
       "13 2018-02-01  1854.92        1  2018      2  1.047784  0.934584   \n",
       "14 2018-03-01  1795.07        1  2018      3  1.013977  1.070109   \n",
       "15 2018-04-01  1791.56        2  2018      4  1.011994  1.005148   \n",
       "16 2018-05-01  1876.14        2  2018      5  1.059771  1.056178   \n",
       "17 2018-06-01  1563.61        2  2018      6  0.883232  1.013425   \n",
       "18 2018-07-01  1830.67        3  2018      7  1.034086  0.990385   \n",
       "19 2018-08-01  1508.25        3  2018      8  0.851961  0.837916   \n",
       "20 2018-09-01  1956.76        3  2018      9  1.105310  1.057225   \n",
       "21 2018-10-01  2133.19        4  2018     10  1.204970  1.284370   \n",
       "22 2018-11-01  1813.04        4  2018     11  1.024127  1.060976   \n",
       "23 2018-12-01  1203.39        4  2018     12  0.679756  0.692350   \n",
       "\n",
       "    D_Seasonalised_trend  Level_index1  Level_index2  \n",
       "0            1947.402409      0.841589      1.003384  \n",
       "1            1872.416839      0.841589      1.003384  \n",
       "2            2242.220419      0.841589      1.003384  \n",
       "3            2115.957015      0.841589      1.003384  \n",
       "4            2123.221263      0.841589      1.003384  \n",
       "5            2404.164082      0.841589      1.003384  \n",
       "6            2036.460337      0.841589      1.003384  \n",
       "7            2094.756233      0.841589      1.003384  \n",
       "8            2033.568875      0.841589      1.003384  \n",
       "9            2262.174524      0.841589      1.003384  \n",
       "10           2204.460646      0.841589      1.003384  \n",
       "11           2169.221130      0.841589      1.003384  \n",
       "12           1922.445867      0.841589      1.003384  \n",
       "13           1984.755644      0.841589      1.003384  \n",
       "14           1677.464807      0.841589      1.003384  \n",
       "15           1782.384254      0.841589      1.003384  \n",
       "16           1776.347978      0.841589      1.003384  \n",
       "17           1542.896603      0.841589      1.003384  \n",
       "18           1848.442567      0.841589      1.003384  \n",
       "19           1800.001190      0.841589      1.003384  \n",
       "20           1850.845248      0.841589      1.003384  \n",
       "21           1660.883806      0.841589      1.003384  \n",
       "22           1708.841552      0.841589      1.003384  \n",
       "23           1738.124070      0.841589      1.003384  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.index=range(len(Train))\n",
    "Train[\"ID\"]=range(1,(len(Train)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train[\"Deleveled_series\"]=Train[\"D_Seasonalised_trend\"]*Train[\"Level_index1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "X =Train[[\"ID\"]] # In case of no extra variable in the dataset, remove the extra variable name from the list, then append the line with \".reshape(-1, 1)\"\n",
    "Y = np.array(Train[\"Deleveled_series\"]).reshape(-1,1)\n",
    "\n",
    "model = lm.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test[\"ID\"]=range(len(Train)+1,len(Train)+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25\n",
       "1    26\n",
       "2    27\n",
       "3    28\n",
       "4    29\n",
       "5    30\n",
       "6    31\n",
       "7    32\n",
       "8    33\n",
       "Name: ID, dtype: int32"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=np.array(Test[[\"ID\"]]) # In case of no extra variable in the dataset, remove the extra variable name from the list, then append the line with \".reshape(-1, 1)\"\n",
    "Y_test=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred1 = Y_test*Train.iloc[0][\"Level_index2\"]*np.array(Train.iloc[0:len(Y_test)][\"F_SI\"]).reshape(-1,1)\n",
    "Test[\"Predictions\"]=Pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99733367],\n",
       "       [0.93458356],\n",
       "       [1.07010889],\n",
       "       [1.00514802],\n",
       "       [1.05617819],\n",
       "       [1.01342501],\n",
       "       [0.99038511],\n",
       "       [0.83791611],\n",
       "       [1.05722507]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Train.iloc[0:len(Y_test)][\"F_SI\"]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1414.504685\n",
       "1    1308.434303\n",
       "2    1478.623767\n",
       "3    1370.502221\n",
       "4    1420.786978\n",
       "5    1344.761723\n",
       "6    1296.096867\n",
       "7    1081.256926\n",
       "8    1344.942673\n",
       "Name: Predictions, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test[\"Predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
